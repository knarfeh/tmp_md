<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Frank&#39;s Private Notes</title>
  
  <link href="/tmp_md/atom.xml" rel="self"/>
  
  <link href="http://knarfeh.github.io/tmp_md/"/>
  <updated>2016-12-12T15:54:02.000Z</updated>
  <id>http://knarfeh.github.io/tmp_md/</id>
  
  <author>
    <name>Frank</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>redis, kafka 测试指北</title>
    <link href="http://knarfeh.github.io/tmp_md/2016/11/22/redis,%20kafka%20%E6%B5%8B%E8%AF%95%E6%8C%87%E5%8C%97/"/>
    <id>http://knarfeh.github.io/tmp_md/2016/11/22/redis, kafka 测试指北/</id>
    <published>2016-11-22T09:42:21.000Z</published>
    <updated>2016-12-12T15:54:02.000Z</updated>
    
    <content type="html">&lt;h1 id=&quot;redis-集群&quot;&gt;&lt;a href=&quot;#redis-集群&quot; class=&quot;headerlink&quot; title=&quot;redis 集群&quot;&gt;&lt;/a&gt;redis 集群&lt;/h1&gt;&lt;p&gt;这里的 redis 集群是广义的，包括 master-slave replication 和 redis clustering，&lt;/p&gt;
&lt;h2 id=&quot;redis-replication&quot;&gt;&lt;a href=&quot;#redis-replication&quot; class=&quot;headerlink&quot; title=&quot;redis replication&quot;&gt;&lt;/a&gt;redis replication&lt;/h2&gt;&lt;h3 id=&quot;功能说明：&quot;&gt;&lt;a href=&quot;#功能说明：&quot; class=&quot;headerlink&quot; title=&quot;功能说明：&quot;&gt;&lt;/a&gt;功能说明：&lt;/h3&gt;&lt;p&gt;实现 redis 的主从复制功能，一个主服务器（只能有一个 master）可以有多个从服务器，master 可以用来进行读，写，slave 机器可以用来进行读。&lt;/p&gt;
&lt;p&gt;部署成功后，分别登陆到 master，slave 的机器上，大致是这样的：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://7xi5vu.com1.z0.glb.clouddn.com/2016-12-12/alauda-redis-master-slave.png&quot; alt=&quot;alauda-redis-master-slave&quot;&gt;&lt;/p&gt;
&lt;h3 id=&quot;refer&quot;&gt;&lt;a href=&quot;#refer&quot; class=&quot;headerlink&quot; title=&quot;refer:&quot;&gt;&lt;/a&gt;refer:&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https://redis.io/topics/replication&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;https://redis.io/topics/replication&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://redisdoc.com/topic/replication.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://redisdoc.com/topic/replication.html&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;redis-cluster-mode&quot;&gt;&lt;a href=&quot;#redis-cluster-mode&quot; class=&quot;headerlink&quot; title=&quot;redis cluster mode&quot;&gt;&lt;/a&gt;redis cluster mode&lt;/h2&gt;&lt;h3 id=&quot;功能说明：-1&quot;&gt;&lt;a href=&quot;#功能说明：-1&quot; class=&quot;headerlink&quot; title=&quot;功能说明：&quot;&gt;&lt;/a&gt;功能说明：&lt;/h3&gt;&lt;p&gt;实现 redis 3.0 版之后的 cluster 的功能。目前至少需要6台打标签的机器&lt;/p&gt;
&lt;p&gt;部署成功后，用 redis 客户端连接到任意一个节点，输入 &lt;code&gt;cluster nodes&lt;/code&gt; 可以看到集群的信息&lt;/p&gt;
&lt;h3 id=&quot;refer：&quot;&gt;&lt;a href=&quot;#refer：&quot; class=&quot;headerlink&quot; title=&quot;refer：&quot;&gt;&lt;/a&gt;refer：&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https://redis.io/topics/cluster-tutorial&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;https://redis.io/topics/cluster-tutorial&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://redisdoc.com/topic/cluster-tutorial.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://redisdoc.com/topic/cluster-tutorial.html&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&quot;kafka-集群&quot;&gt;&lt;a href=&quot;#kafka-集群&quot; class=&quot;headerlink&quot; title=&quot;kafka 集群&quot;&gt;&lt;/a&gt;kafka 集群&lt;/h1&gt;&lt;p&gt;&lt;strong&gt;注意事项&lt;/strong&gt; 需要提前通过 app catalog 部署 zookeeper，因为 kafka  集群依赖于 zookeeper 协调。&lt;/p&gt;
&lt;p&gt;部署成功后，利用 &lt;a href=&quot;http://kafka-python.readthedocs.io/en/master/usage.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;kafka-python&lt;/a&gt; 进行测试：&lt;/p&gt;
&lt;p&gt;producer.py:&lt;/p&gt;
&lt;figure class=&quot;highlight oxygene&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;21&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;22&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;23&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;24&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;25&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;26&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;from&lt;/span&gt; kafka import KafkaProducer&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;from&lt;/span&gt; kafka.errors import KafkaError&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;producer = KafkaProducer(bootstrap_servers=[&lt;span class=&quot;string&quot;&gt;&#39;localhost:9092&#39;&lt;/span&gt;])&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;# Asynchronous &lt;span class=&quot;keyword&quot;&gt;by&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;default&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;future&lt;/span&gt; = producer.send(&lt;span class=&quot;string&quot;&gt;&#39;my-topic&#39;&lt;/span&gt;, b&lt;span class=&quot;string&quot;&gt;&#39;raw_bytes&#39;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;# &lt;span class=&quot;keyword&quot;&gt;Block&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;string&quot;&gt;&#39;synchronous&#39;&lt;/span&gt; sends&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;try&lt;/span&gt;:&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    record_metadata = &lt;span class=&quot;keyword&quot;&gt;future&lt;/span&gt;.get(timeout=&lt;span class=&quot;number&quot;&gt;10&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;except&lt;/span&gt; KafkaError:&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    # Decide what &lt;span class=&quot;keyword&quot;&gt;to&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;do&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;if&lt;/span&gt; produce request failed...&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    log.exception()&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    pass&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;# Successful &lt;span class=&quot;keyword&quot;&gt;result&lt;/span&gt; returns assigned partition &lt;span class=&quot;keyword&quot;&gt;and&lt;/span&gt; offset&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;print (record_metadata.topic)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;print (record_metadata.partition)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;print (record_metadata.offset)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;# produce keyed messages &lt;span class=&quot;keyword&quot;&gt;to&lt;/span&gt; enable hashed partitioning&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;producer.send(&lt;span class=&quot;string&quot;&gt;&#39;my-topic&#39;&lt;/span&gt;, key=b&lt;span class=&quot;string&quot;&gt;&#39;foo&#39;&lt;/span&gt;, value=b&lt;span class=&quot;string&quot;&gt;&#39;bar&#39;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;```  &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;consumer.py:&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;from kafka import KafkaConsumer&lt;/p&gt;
&lt;h1 id=&quot;To-consume-latest-messages-and-auto-commit-offsets&quot;&gt;&lt;a href=&quot;#To-consume-latest-messages-and-auto-commit-offsets&quot; class=&quot;headerlink&quot; title=&quot;To consume latest messages and auto-commit offsets&quot;&gt;&lt;/a&gt;To consume latest messages and auto-commit offsets&lt;/h1&gt;&lt;p&gt;consumer = KafkaConsumer(‘my-topic’,&lt;br&gt;                         group_id=’my-group’,&lt;br&gt;                         bootstrap_servers=[‘localhost:9092’])&lt;br&gt;for message in consumer:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# message value and key are raw bytes -- decode if necessary!
# e.g., for unicode: `message.value.decode(&amp;apos;utf-8&amp;apos;)`
print (&amp;quot;%s:%d:%d: key=%s value=%s&amp;quot; % (message.topic, message.partition,
                                      message.offset, message.key,
                                      message.value))
&lt;/code&gt;&lt;/pre&gt;&lt;h1 id=&quot;consume-earliest-available-messages-don’t-commit-offsets&quot;&gt;&lt;a href=&quot;#consume-earliest-available-messages-don’t-commit-offsets&quot; class=&quot;headerlink&quot; title=&quot;consume earliest available messages, don’t commit offsets&quot;&gt;&lt;/a&gt;consume earliest available messages, don’t commit offsets&lt;/h1&gt;&lt;p&gt;KafkaConsumer(auto_offset_reset=’earliest’, enable_auto_commit=False)&lt;/p&gt;
&lt;h1 id=&quot;consume-json-messages&quot;&gt;&lt;a href=&quot;#consume-json-messages&quot; class=&quot;headerlink&quot; title=&quot;consume json messages&quot;&gt;&lt;/a&gt;consume json messages&lt;/h1&gt;&lt;p&gt;KafkaConsumer(value_deserializer=lambda m: json.loads(m.decode(‘ascii’)))&lt;/p&gt;
&lt;h1 id=&quot;consume-msgpack&quot;&gt;&lt;a href=&quot;#consume-msgpack&quot; class=&quot;headerlink&quot; title=&quot;consume msgpack&quot;&gt;&lt;/a&gt;consume msgpack&lt;/h1&gt;&lt;p&gt;KafkaConsumer(value_deserializer=msgpack.unpackb)&lt;/p&gt;
&lt;h1 id=&quot;StopIteration-if-no-message-after-1sec&quot;&gt;&lt;a href=&quot;#StopIteration-if-no-message-after-1sec&quot; class=&quot;headerlink&quot; title=&quot;StopIteration if no message after 1sec&quot;&gt;&lt;/a&gt;StopIteration if no message after 1sec&lt;/h1&gt;&lt;p&gt;KafkaConsumer(consumer_timeout_ms=1000)&lt;/p&gt;
&lt;h1 id=&quot;Subscribe-to-a-regex-topic-pattern&quot;&gt;&lt;a href=&quot;#Subscribe-to-a-regex-topic-pattern&quot; class=&quot;headerlink&quot; title=&quot;Subscribe to a regex topic pattern&quot;&gt;&lt;/a&gt;Subscribe to a regex topic pattern&lt;/h1&gt;&lt;p&gt;consumer = KafkaConsumer()&lt;br&gt;consumer.subscribe(pattern=’^awesome.*’)&lt;/p&gt;
&lt;h1 id=&quot;Use-multiple-consumers-in-parallel-w-0-9-kafka-brokers&quot;&gt;&lt;a href=&quot;#Use-multiple-consumers-in-parallel-w-0-9-kafka-brokers&quot; class=&quot;headerlink&quot; title=&quot;Use multiple consumers in parallel w/ 0.9 kafka brokers&quot;&gt;&lt;/a&gt;Use multiple consumers in parallel w/ 0.9 kafka brokers&lt;/h1&gt;&lt;h1 id=&quot;typically-you-would-run-each-on-a-different-server-process-CPU&quot;&gt;&lt;a href=&quot;#typically-you-would-run-each-on-a-different-server-process-CPU&quot; class=&quot;headerlink&quot; title=&quot;typically you would run each on a different server / process / CPU&quot;&gt;&lt;/a&gt;typically you would run each on a different server / process / CPU&lt;/h1&gt;&lt;p&gt;consumer1 = KafkaConsumer(‘my-topic’,&lt;br&gt;                          group_id=’my-group’,&lt;br&gt;                          bootstrap_servers=’my.server.com’)&lt;br&gt;consumer2 = KafkaConsumer(‘my-topic’,&lt;br&gt;                          group_id=’my-group’,&lt;br&gt;                          bootstrap_servers=’my.server.com’)&lt;br&gt;```&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;redis-集群&quot;&gt;&lt;a href=&quot;#redis-集群&quot; class=&quot;headerlink&quot; title=&quot;redis 集群&quot;&gt;&lt;/a&gt;redis 集群&lt;/h1&gt;&lt;p&gt;这里的 redis 集群是广义的，包括 master-slave replication 和
    
    </summary>
    
    
      <category term="tmp_md" scheme="http://knarfeh.github.io/tmp_md/tags/tmp-md/"/>
    
  </entry>
  
</feed>
